# CMAKE generated file: DO NOT EDIT!
# Generated by "Ninja" Generator, CMake Version 4.2

# This file contains all the build statements describing the
# compilation DAG.

# =============================================================================
# Write statements declared in CMakeLists.txt:
# 
# Which is the root file.
# =============================================================================

# =============================================================================
# Project: cuda_llm_storage_pipeline
# Configurations: Release
# =============================================================================

#############################################
# Minimal version of Ninja required by this file

ninja_required_version = 1.5


#############################################
# Set configuration variable for custom commands.

CONFIGURATION = Release
# =============================================================================
# Include auxiliary files.


#############################################
# Include rules file.

include CMakeFiles/rules.ninja

# =============================================================================

#############################################
# Logical path to working directory; prefix for absolute paths.

cmake_ninja_workdir = /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/build/
# =============================================================================
# Object build statements for STATIC_LIBRARY target slp_core


#############################################
# Order-only phony target for slp_core

build cmake_object_order_depends_target_slp_core: phony || .

build CMakeFiles/slp_core.dir/src/http_client.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/http_client.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/http_client.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/sha256.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/sha256.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/sha256.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/seaweed/lookup.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/seaweed/lookup.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/seaweed/lookup.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/seaweed
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/seaweed/assign.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/seaweed/assign.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/seaweed/assign.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/seaweed
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/seaweed/file_upload.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/seaweed/file_upload.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/seaweed/file_upload.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/seaweed
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/seaweed/file_download.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/seaweed/file_download.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/seaweed/file_download.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/seaweed
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/seaweed/filer.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/seaweed/filer.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/seaweed/filer.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/seaweed
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/artifact/manifest.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/artifact/manifest.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/artifact/manifest.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/artifact
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/artifact/registry.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/artifact/registry.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/artifact/registry.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/artifact
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/artifact/paths.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/artifact/paths.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/artifact/paths.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/artifact
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/pipeline/model_store.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/pipeline/model_store.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/pipeline/model_store.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/pipeline
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/pipeline/prompt_store.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/pipeline/prompt_store.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/pipeline/prompt_store.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/pipeline
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/pipeline/result_store.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/pipeline/result_store.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/pipeline/result_store.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/pipeline
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

build CMakeFiles/slp_core.dir/src/pipeline/run_id.cpp.o: CXX_COMPILER__slp_core_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/src/pipeline/run_id.cpp || cmake_object_order_depends_target_slp_core
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_core.dir/src/pipeline/run_id.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_core.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_core.dir/src/pipeline
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir


# =============================================================================
# Link build statements for STATIC_LIBRARY target slp_core


#############################################
# Link the static library libslp_core.a

build libslp_core.a: CXX_STATIC_LIBRARY_LINKER__slp_core_Release CMakeFiles/slp_core.dir/src/http_client.cpp.o CMakeFiles/slp_core.dir/src/sha256.cpp.o CMakeFiles/slp_core.dir/src/seaweed/lookup.cpp.o CMakeFiles/slp_core.dir/src/seaweed/assign.cpp.o CMakeFiles/slp_core.dir/src/seaweed/file_upload.cpp.o CMakeFiles/slp_core.dir/src/seaweed/file_download.cpp.o CMakeFiles/slp_core.dir/src/seaweed/filer.cpp.o CMakeFiles/slp_core.dir/src/artifact/manifest.cpp.o CMakeFiles/slp_core.dir/src/artifact/registry.cpp.o CMakeFiles/slp_core.dir/src/artifact/paths.cpp.o CMakeFiles/slp_core.dir/src/pipeline/model_store.cpp.o CMakeFiles/slp_core.dir/src/pipeline/prompt_store.cpp.o CMakeFiles/slp_core.dir/src/pipeline/result_store.cpp.o CMakeFiles/slp_core.dir/src/pipeline/run_id.cpp.o
  CONFIG = Release
  LANGUAGE_COMPILE_FLAGS = -O3 -DNDEBUG
  OBJECT_DIR = CMakeFiles/slp_core.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = libslp_core.a
  TARGET_PDB = slp_core.a.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_core.dir

# =============================================================================
# Object build statements for EXECUTABLE target slp_put_model


#############################################
# Order-only phony target for slp_put_model

build cmake_object_order_depends_target_slp_put_model: phony || cmake_object_order_depends_target_slp_core

build CMakeFiles/slp_put_model.dir/apps/slp_put_model.cpp.o: CXX_COMPILER__slp_put_model_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/apps/slp_put_model.cpp || cmake_object_order_depends_target_slp_put_model
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_put_model.dir/apps/slp_put_model.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_put_model.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_put_model.dir/apps
  TARGET_SUPPORT_DIR = CMakeFiles/slp_put_model.dir


# =============================================================================
# Link build statements for EXECUTABLE target slp_put_model


#############################################
# Link the executable slp_put_model

build slp_put_model: CXX_EXECUTABLE_LINKER__slp_put_model_Release CMakeFiles/slp_put_model.dir/apps/slp_put_model.cpp.o | libslp_core.a /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libcurl.so || libslp_core.a
  CONFIG = Release
  FLAGS = -O3 -DNDEBUG
  LINK_LIBRARIES = libslp_core.a  /usr/lib/x86_64-linux-gnu/libcurl.so  /usr/lib/x86_64-linux-gnu/libcurl.so
  OBJECT_DIR = CMakeFiles/slp_put_model.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = slp_put_model
  TARGET_PDB = slp_put_model.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_put_model.dir

# =============================================================================
# Object build statements for EXECUTABLE target slp_get_model


#############################################
# Order-only phony target for slp_get_model

build cmake_object_order_depends_target_slp_get_model: phony || cmake_object_order_depends_target_slp_core

build CMakeFiles/slp_get_model.dir/apps/slp_get_model.cpp.o: CXX_COMPILER__slp_get_model_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/apps/slp_get_model.cpp || cmake_object_order_depends_target_slp_get_model
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_get_model.dir/apps/slp_get_model.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_get_model.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_get_model.dir/apps
  TARGET_SUPPORT_DIR = CMakeFiles/slp_get_model.dir


# =============================================================================
# Link build statements for EXECUTABLE target slp_get_model


#############################################
# Link the executable slp_get_model

build slp_get_model: CXX_EXECUTABLE_LINKER__slp_get_model_Release CMakeFiles/slp_get_model.dir/apps/slp_get_model.cpp.o | libslp_core.a /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libcurl.so || libslp_core.a
  CONFIG = Release
  FLAGS = -O3 -DNDEBUG
  LINK_LIBRARIES = libslp_core.a  /usr/lib/x86_64-linux-gnu/libcurl.so  /usr/lib/x86_64-linux-gnu/libcurl.so
  OBJECT_DIR = CMakeFiles/slp_get_model.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = slp_get_model
  TARGET_PDB = slp_get_model.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_get_model.dir

# =============================================================================
# Object build statements for EXECUTABLE target slp_put_prompts


#############################################
# Order-only phony target for slp_put_prompts

build cmake_object_order_depends_target_slp_put_prompts: phony || cmake_object_order_depends_target_slp_core

build CMakeFiles/slp_put_prompts.dir/apps/slp_put_prompts.cpp.o: CXX_COMPILER__slp_put_prompts_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/apps/slp_put_prompts.cpp || cmake_object_order_depends_target_slp_put_prompts
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_put_prompts.dir/apps/slp_put_prompts.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_put_prompts.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_put_prompts.dir/apps
  TARGET_SUPPORT_DIR = CMakeFiles/slp_put_prompts.dir


# =============================================================================
# Link build statements for EXECUTABLE target slp_put_prompts


#############################################
# Link the executable slp_put_prompts

build slp_put_prompts: CXX_EXECUTABLE_LINKER__slp_put_prompts_Release CMakeFiles/slp_put_prompts.dir/apps/slp_put_prompts.cpp.o | libslp_core.a /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libcurl.so || libslp_core.a
  CONFIG = Release
  FLAGS = -O3 -DNDEBUG
  LINK_LIBRARIES = libslp_core.a  /usr/lib/x86_64-linux-gnu/libcurl.so  /usr/lib/x86_64-linux-gnu/libcurl.so
  OBJECT_DIR = CMakeFiles/slp_put_prompts.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = slp_put_prompts
  TARGET_PDB = slp_put_prompts.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_put_prompts.dir

# =============================================================================
# Object build statements for EXECUTABLE target slp_run_infer


#############################################
# Order-only phony target for slp_run_infer

build cmake_object_order_depends_target_slp_run_infer: phony || cmake_object_order_depends_target_slp_core

build CMakeFiles/slp_run_infer.dir/apps/slp_run_infer.cpp.o: CXX_COMPILER__slp_run_infer_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/apps/slp_run_infer.cpp || cmake_object_order_depends_target_slp_run_infer
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_run_infer.dir/apps/slp_run_infer.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_run_infer.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_run_infer.dir/apps
  TARGET_SUPPORT_DIR = CMakeFiles/slp_run_infer.dir


# =============================================================================
# Link build statements for EXECUTABLE target slp_run_infer


#############################################
# Link the executable slp_run_infer

build slp_run_infer: CXX_EXECUTABLE_LINKER__slp_run_infer_Release CMakeFiles/slp_run_infer.dir/apps/slp_run_infer.cpp.o | libslp_core.a /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libcurl.so || libslp_core.a
  CONFIG = Release
  FLAGS = -O3 -DNDEBUG
  LINK_LIBRARIES = libslp_core.a  /usr/lib/x86_64-linux-gnu/libcurl.so  /usr/lib/x86_64-linux-gnu/libcurl.so
  OBJECT_DIR = CMakeFiles/slp_run_infer.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = slp_run_infer
  TARGET_PDB = slp_run_infer.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_run_infer.dir

# =============================================================================
# Object build statements for EXECUTABLE target slp_bench_storage


#############################################
# Order-only phony target for slp_bench_storage

build cmake_object_order_depends_target_slp_bench_storage: phony || cmake_object_order_depends_target_slp_core

build CMakeFiles/slp_bench_storage.dir/apps/slp_bench_storage.cpp.o: CXX_COMPILER__slp_bench_storage_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/apps/slp_bench_storage.cpp || cmake_object_order_depends_target_slp_bench_storage
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_bench_storage.dir/apps/slp_bench_storage.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  INCLUDES = -I/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/include
  OBJECT_DIR = CMakeFiles/slp_bench_storage.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_bench_storage.dir/apps
  TARGET_SUPPORT_DIR = CMakeFiles/slp_bench_storage.dir


# =============================================================================
# Link build statements for EXECUTABLE target slp_bench_storage


#############################################
# Link the executable slp_bench_storage

build slp_bench_storage: CXX_EXECUTABLE_LINKER__slp_bench_storage_Release CMakeFiles/slp_bench_storage.dir/apps/slp_bench_storage.cpp.o | libslp_core.a /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libcurl.so || libslp_core.a
  CONFIG = Release
  FLAGS = -O3 -DNDEBUG
  LINK_LIBRARIES = libslp_core.a  /usr/lib/x86_64-linux-gnu/libcurl.so  /usr/lib/x86_64-linux-gnu/libcurl.so
  OBJECT_DIR = CMakeFiles/slp_bench_storage.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = slp_bench_storage
  TARGET_PDB = slp_bench_storage.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_bench_storage.dir

# =============================================================================
# Object build statements for EXECUTABLE target slp_llama_client


#############################################
# Order-only phony target for slp_llama_client

build cmake_object_order_depends_target_slp_llama_client: phony || .

build CMakeFiles/slp_llama_client.dir/apps/slp_llama_client.cpp.o: CXX_COMPILER__slp_llama_client_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/apps/slp_llama_client.cpp || cmake_object_order_depends_target_slp_llama_client
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_llama_client.dir/apps/slp_llama_client.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  OBJECT_DIR = CMakeFiles/slp_llama_client.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_llama_client.dir/apps
  TARGET_SUPPORT_DIR = CMakeFiles/slp_llama_client.dir


# =============================================================================
# Link build statements for EXECUTABLE target slp_llama_client


#############################################
# Link the executable slp_llama_client

build slp_llama_client: CXX_EXECUTABLE_LINKER__slp_llama_client_Release CMakeFiles/slp_llama_client.dir/apps/slp_llama_client.cpp.o | /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libcurl.so
  CONFIG = Release
  FLAGS = -O3 -DNDEBUG
  LINK_LIBRARIES = /usr/lib/x86_64-linux-gnu/libcurl.so  /usr/lib/x86_64-linux-gnu/libcurl.so
  OBJECT_DIR = CMakeFiles/slp_llama_client.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = slp_llama_client
  TARGET_PDB = slp_llama_client.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_llama_client.dir

# =============================================================================
# Object build statements for EXECUTABLE target slp_llama_batch


#############################################
# Order-only phony target for slp_llama_batch

build cmake_object_order_depends_target_slp_llama_batch: phony || .

build CMakeFiles/slp_llama_batch.dir/apps/slp_llama_batch.cpp.o: CXX_COMPILER__slp_llama_batch_unscanned_Release /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/apps/slp_llama_batch.cpp || cmake_object_order_depends_target_slp_llama_batch
  CONFIG = Release
  DEP_FILE = CMakeFiles/slp_llama_batch.dir/apps/slp_llama_batch.cpp.o.d
  FLAGS = -O3 -DNDEBUG -std=gnu++20 -Wall -Wextra -Wpedantic -Wshadow -Wconversion
  OBJECT_DIR = CMakeFiles/slp_llama_batch.dir
  OBJECT_FILE_DIR = CMakeFiles/slp_llama_batch.dir/apps
  TARGET_SUPPORT_DIR = CMakeFiles/slp_llama_batch.dir


# =============================================================================
# Link build statements for EXECUTABLE target slp_llama_batch


#############################################
# Link the executable slp_llama_batch

build slp_llama_batch: CXX_EXECUTABLE_LINKER__slp_llama_batch_Release CMakeFiles/slp_llama_batch.dir/apps/slp_llama_batch.cpp.o | /usr/lib/x86_64-linux-gnu/libcurl.so /usr/lib/x86_64-linux-gnu/libcurl.so
  CONFIG = Release
  FLAGS = -O3 -DNDEBUG
  LINK_LIBRARIES = /usr/lib/x86_64-linux-gnu/libcurl.so  /usr/lib/x86_64-linux-gnu/libcurl.so
  OBJECT_DIR = CMakeFiles/slp_llama_batch.dir
  POST_BUILD = :
  PRE_LINK = :
  TARGET_FILE = slp_llama_batch
  TARGET_PDB = slp_llama_batch.dbg
  TARGET_SUPPORT_DIR = CMakeFiles/slp_llama_batch.dir


#############################################
# Utility command for edit_cache

build CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cd /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/build && /usr/local/bin/ccmake -S/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline -B/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/build
  DESC = Running CMake cache editor...
  pool = console
  restat = 1

build edit_cache: phony CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cd /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/build && /usr/local/bin/cmake --regenerate-during-build -S/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline -B/media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/build
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build rebuild_cache: phony CMakeFiles/rebuild_cache.util

# =============================================================================
# Target aliases.

build slp_core: phony libslp_core.a

# =============================================================================
# Folder targets.

# =============================================================================

#############################################
# Folder: /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/build

build all: phony libslp_core.a slp_put_model slp_get_model slp_put_prompts slp_run_infer slp_bench_storage slp_llama_client slp_llama_batch

# =============================================================================
# Built-in targets


#############################################
# Re-run CMake if any of its inputs changed.

build build.ninja /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/build/cmake_install.cmake: RERUN_CMAKE | /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/CMakeLists.txt /usr/local/share/cmake-4.2/Modules/CMakeCXXInformation.cmake /usr/local/share/cmake-4.2/Modules/CMakeCommonLanguageInclude.cmake /usr/local/share/cmake-4.2/Modules/CMakeGenericSystem.cmake /usr/local/share/cmake-4.2/Modules/CMakeInitializeConfigs.cmake /usr/local/share/cmake-4.2/Modules/CMakeLanguageInformation.cmake /usr/local/share/cmake-4.2/Modules/CMakeSystemSpecificInformation.cmake /usr/local/share/cmake-4.2/Modules/CMakeSystemSpecificInitialize.cmake /usr/local/share/cmake-4.2/Modules/Compiler/CMakeCommonCompilerMacros.cmake /usr/local/share/cmake-4.2/Modules/Compiler/GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Compiler/GNU.cmake /usr/local/share/cmake-4.2/Modules/FindCURL.cmake /usr/local/share/cmake-4.2/Modules/FindPackageHandleStandardArgs.cmake /usr/local/share/cmake-4.2/Modules/FindPackageMessage.cmake /usr/local/share/cmake-4.2/Modules/FindPkgConfig.cmake /usr/local/share/cmake-4.2/Modules/Internal/CMakeCXXLinkerInformation.cmake /usr/local/share/cmake-4.2/Modules/Internal/CMakeCommonLinkerInformation.cmake /usr/local/share/cmake-4.2/Modules/Linker/GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Linker/GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linker/GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linker/Linux-GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linker/Linux-GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux-GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux-GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux-Initialize.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux.cmake /usr/local/share/cmake-4.2/Modules/Platform/UnixPaths.cmake /usr/local/share/cmake-4.2/Modules/SelectLibraryConfigurations.cmake CMakeCache.txt CMakeFiles/4.2.1/CMakeCXXCompiler.cmake CMakeFiles/4.2.1/CMakeSystem.cmake
  pool = console


#############################################
# A missing CMake input file is not an error.

build /media/waqasm86/External1/Project-CPP/Project-Nvidia/cuda-llm-storage-pipeline/CMakeLists.txt /usr/local/share/cmake-4.2/Modules/CMakeCXXInformation.cmake /usr/local/share/cmake-4.2/Modules/CMakeCommonLanguageInclude.cmake /usr/local/share/cmake-4.2/Modules/CMakeGenericSystem.cmake /usr/local/share/cmake-4.2/Modules/CMakeInitializeConfigs.cmake /usr/local/share/cmake-4.2/Modules/CMakeLanguageInformation.cmake /usr/local/share/cmake-4.2/Modules/CMakeSystemSpecificInformation.cmake /usr/local/share/cmake-4.2/Modules/CMakeSystemSpecificInitialize.cmake /usr/local/share/cmake-4.2/Modules/Compiler/CMakeCommonCompilerMacros.cmake /usr/local/share/cmake-4.2/Modules/Compiler/GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Compiler/GNU.cmake /usr/local/share/cmake-4.2/Modules/FindCURL.cmake /usr/local/share/cmake-4.2/Modules/FindPackageHandleStandardArgs.cmake /usr/local/share/cmake-4.2/Modules/FindPackageMessage.cmake /usr/local/share/cmake-4.2/Modules/FindPkgConfig.cmake /usr/local/share/cmake-4.2/Modules/Internal/CMakeCXXLinkerInformation.cmake /usr/local/share/cmake-4.2/Modules/Internal/CMakeCommonLinkerInformation.cmake /usr/local/share/cmake-4.2/Modules/Linker/GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Linker/GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linker/GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linker/Linux-GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linker/Linux-GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux-GNU-CXX.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux-GNU.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux-Initialize.cmake /usr/local/share/cmake-4.2/Modules/Platform/Linux.cmake /usr/local/share/cmake-4.2/Modules/Platform/UnixPaths.cmake /usr/local/share/cmake-4.2/Modules/SelectLibraryConfigurations.cmake CMakeCache.txt CMakeFiles/4.2.1/CMakeCXXCompiler.cmake CMakeFiles/4.2.1/CMakeSystem.cmake: phony


#############################################
# Clean all the built files.

build clean: CLEAN


#############################################
# Print all primary targets available.

build help: HELP


#############################################
# Make the all target the default.

default all
